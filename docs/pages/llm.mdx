import Code, {Python, Typescript} from "components/Code";

# LLM APIs

We support OpenAI and Anthropic APIs out of the box, though Anthropic models tend to work better with XML data.

## Anthropic

<Code>
<Python>
```python
from xmlai.llm import anthropic_prompt

prompt = anthropic_prompt(
    {
        "question": "what is the answer to the ultimate question of life?",
        "reference": "The Hitchhiker's Guide to the Galaxy",
    },
    response_root_tag="answer",
)

completion = anthropic.completions.create(
    model="claude-instant-1",
    max_tokens_to_sample=300,
    temperature=0.1,
    **prompt,
)

completion.completion # 42
```
</Python>
<Typescript>
```typescript
import { anthropicPrompt } from "xmlai/llm";

const prompt = anthropicPrompt(
    {
        question: "what is the answer to the ultimate question of life?",
        reference: "The Hitchhiker's Guide to the Galaxy",
    },
    response_root_tag="answer"
);

const completion = await anthropic.completions.create({
    model: "claude-instant-1",
    max_tokens_to_sample: 300,
    temperature: 0.1,
    ...prompt,
});

completion.completion // 42
```
</Typescript>
</Code>

The generated prompts look like this:
```json
{
   "prompt":"\n\nHuman:<question>what is the answer to the ultimate question of life?</question>
   <reference>The Hitchhiker's Guide to the Galaxy</reference>\n\nAssistant:<answer>",
   "stop_sequences":[
      "</answer>"
   ]
}
```
